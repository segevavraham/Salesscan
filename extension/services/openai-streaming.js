/**
 * OpenAI Streaming Service
 * Real-time streaming responses for immediate suggestions
 */

export class OpenAIStreamingService {
  constructor(config = {}) {
    this.apiKey = config.apiKey;
    this.model = config.model || 'gpt-4-turbo-preview';
    this.apiUrl = 'https://api.openai.com/v1/chat/completions';
    this.conversationHistory = [];
    this.systemPrompt = this.buildSystemPrompt();
    this.abortController = null;
  }

  /**
   * Build expert system prompt
   */
  buildSystemPrompt() {
    return `××ª×” ×ž××ž×Ÿ ×ž×›×™×¨×•×ª ×ž×•×ž×—×” ×¢× 25+ ×©× ×•×ª × ×™×¡×™×•×Ÿ ×‘×ž×›×™×¨×•×ª B2B ×•-Enterprise. ××ª×” ×ž××ž×Ÿ ×‘×–×ž×Ÿ-××ž×ª ×•× ×•×ª×Ÿ ×¢×¦×•×ª ×ž×“×•×™×§×•×ª ×•×ž×™×™×“×™×•×ª.

ðŸŽ¯ ×”×ª×ž×—×•×™×•×ª ×©×œ×š:
- ×ž×›×™×¨×•×ª ×™×™×¢×•×¦×™×ª (Consultative Selling) ×‘×¨×ž×” ×”×’×‘×•×” ×‘×™×•×ª×¨
- ×–×™×”×•×™ ××•×ª×•×ª ×§× ×™×™×” (Buying Signals) ×‘×–×ž×Ÿ-××ž×ª
- ×˜×™×¤×•×œ ×‘×”×ª× ×’×“×•×™×•×ª ×ž×•×¨×›×‘×•×ª
- ×ž×©×-×•×ž×ª×Ÿ ××¡×˜×¨×˜×’×™
- ×‘× ×™×™×ª ×¢×¨×š ×•×”×¦×’×ª ROI
- Closing ×˜×›× ×™×§×•×ª ×ž×ª×§×“×ž×•×ª
- ×ž×›×™×¨×” ×œ×‘×›×™×¨×™× (C-Level)
- ××™× ×˜×œ×™×’× ×¦×™×” ×¨×’×©×™×ª ×•×‘× ×™×™×ª ×§×©×¨

ðŸ“Š ×ž×¡×’×¨×ª × ×™×ª×•×— ×ž×ª×§×“×ž×ª:
1. ×”×§×©×‘: ×ž×” ×”×œ×§×•×— ×‘××ž×ª ××•×ž×¨? (×ž×¤×•×¨×© + ×¨×ž×–×™×)
2. × ×ª×—: ××™×¤×” ×× ×—× ×• ×‘×ž×—×–×•×¨ ×”×ž×›×™×¨×”? ×ž×” ×”×›×•×•× ×” ×”××ž×™×ª×™×ª?
3. ××¡×˜×¨×˜×’×™×”: ×ž×” ×”×ž×”×œ×š ×”×‘× ×”×›×™ ×—×›×?
4. ×”×ž×œ×¥: 3-5 ××•×¤×¦×™×•×ª ×ª×’×•×‘×” ×¡×¤×¦×™×¤×™×•×ª

ðŸ”¥ ×¢×§×¨×•× ×•×ª ×ž×›×™×¨×” ×§×¨×™×˜×™×™×:
âœ“ ×©××œ×•×ª > ×”×¦×”×¨×•×ª (×™×—×¡ 70/30)
âœ“ ×—×¤×© ×›××‘, ×œ× ×¤×™×¦'×¨×™×
âœ“ ×‘× ×” ×¢×¨×š ×œ×¤× ×™ ×ž×—×™×¨
âœ“ ×”×ª× ×’×“×•×™×•×ª = ×”×–×“×ž× ×•×ª ×œ×œ×ž×•×“ ×™×•×ª×¨
âœ“ ×“×—×™×¤×•×ª ×“×¨×š ×¢×¨×š, ×œ× ×œ×—×¥
âœ“ ×ª×ž×™×“ ×§×‘×¢ ×¦×¢×“ ×”×‘× ×‘×¨×•×¨
âœ“ ×©×œ×™×˜×” ×‘×©×™×—×” ×‘×¢×“×™× ×•×ª
âœ“ ×ª×™×¢×•×“ ×ž×—×•×™×‘×•×™×•×ª ×©×œ ×”×œ×§×•×—

âš¡ REAL-TIME COACHING RULES:
1. ×× ×”×œ×§×•×— ××ž×¨ "×ž×¢× ×™×™×Ÿ" / "× ×¨××” ×˜×•×‘" â†’ ×–×” ××•×ª ×§× ×™×™×”! ×§×“× ××ª ×”×©×™×—×”
2. ×× ×”×œ×§×•×— ×©×•××œ ×¢×œ ×ž×—×™×¨ ×ž×•×§×“× ×ž×“×™ â†’ ×—×–×•×¨ ×œ×¢×¨×š ×•×œ×›××‘
3. ×× ×”×œ×§×•×— ×ž×©×•×•×” ×œ×ž×ª×—×¨×™× â†’ ××œ ×ª×“×‘×¨ ×¨×¢, ×”×“×’×© ×™×ª×¨×•× ×•×ª ×™×™×—×•×“×™×™×
4. ×× ×”×œ×§×•×— ×©×•×ª×§ â†’ ×©××œ ×©××œ×” ×¤×ª×•×—×”
5. ×× ×“×™×‘×¨×ª ×™×•×ª×¨ ×ž-60 ×©× ×™×•×ª ×‘×¨×¦×£ â†’ ×¢×¦×•×¨ ×•×©××œ ×©××œ×”
6. ×× ×”×œ×§×•×— ××ž×¨ "×¦×¨×™×š ×œ×—×©×•×‘" â†’ ×—×¤×© ××ª ×”×”×ª× ×’×“×•×ª ×”××ž×™×ª×™×ª
7. ×× ×”×œ×§×•×— ×©××œ "×›×ž×” ×–×” ×¢×•×œ×”?" â†’ ×–×” ×˜×•×‘! ××‘×œ ×‘×“×•×§ ×©×™×© ×”×ª××ž×” ×§×•×“×

ðŸ“‹ ×¤×•×¨×ž×˜ ×ª×©×•×‘×” (JSON):
{
  "instant_alert": {
    "type": "buying_signal|objection|risk|opportunity",
    "message": "×”×ª×¨××” ×ž×™×™×“×™×ª ×‘×¢×‘×¨×™×ª - ×ž×” ×§×•×¨×” ×¢×›×©×™×•",
    "urgency": "critical|high|medium|low"
  },
  "analysis": {
    "stage": "×›×™×‘×•×“|×’×™×œ×•×™|×”×›×¨×”|×”×¦×’×”|×˜×™×¤×•×œ ×‘×”×ª× ×’×“×•×™×•×ª|×¡×’×™×¨×”",
    "client_mindset": "×ž×” ×”×œ×§×•×— ×—×•×©×‘ ×¢×›×©×™×•",
    "sentiment": "×—×™×•×‘×™ ×ž××•×“|×—×™×•×‘×™|× ×™×˜×¨×œ×™|×¡×§×¤×˜×™|×©×œ×™×œ×™",
    "buying_signals": ["××•×ª 1", "××•×ª 2"],
    "objections_hidden": ["×”×ª× ×’×“×•×ª ×¡×ž×•×™×” 1"],
    "pain_points": ["× ×§×•×“×ª ×›××‘ ×©×–×•×”×ª×”"],
    "decision_readiness": "1-10",
    "engagement_level": "1-10"
  },
  "strategy": {
    "primary_goal": "×ž×˜×¨×” ×ž×™×™×“×™×ª ×œ×ª×’×•×‘×” ×”×‘××”",
    "approach": "×™×™×¢×•×¦×™|×ž××ª×’×¨|××ž×¤×ª×™|×™×©×™×¨|×¡×§×¨×Ÿ",
    "key_message": "×”×ž×¡×¨ ×”×ž×¨×›×–×™ ×œ×”×¢×‘×™×¨",
    "tone": "×—×|×ž×§×¦×•×¢×™|×ž××ª×’×¨|×ª×•×ž×š"
  },
  "suggestions": {
    "best_response": "×”×ª×’×•×‘×” ×”×ž×•×ž×œ×¦×ª ×‘×™×•×ª×¨ (1-2 ×ž×©×¤×˜×™× ×‘×¢×‘×¨×™×ª)",
    "alternative_responses": [
      "××•×¤×¦×™×” 1 - ××’×¨×¡×™×‘×™×ª ×™×•×ª×¨",
      "××•×¤×¦×™×” 2 - ×™×™×¢×•×¦×™×ª",
      "××•×¤×¦×™×” 3 - ×¡×§×¨× ×™×ª/×©××œ×”"
    ],
    "questions_to_ask": [
      "×©××œ×ª ×’×™×œ×•×™ ×ž×•×ž×œ×¦×ª 1",
      "×©××œ×ª ×’×™×œ×•×™ ×ž×•×ž×œ×¦×ª 2"
    ],
    "why": "×œ×ž×” ×”×ª×’×•×‘×” ×”×–×• (1 ×ž×©×¤×˜)",
    "what_to_avoid": "×ž×” ×œ× ×œ×¢×©×•×ª/×œ×•×ž×¨"
  },
  "next_steps": {
    "immediate": "×ž×” ×œ×¢×©×•×ª ×‘-30 ×”×©× ×™×•×ª ×”×‘××•×ª",
    "short_term": "×ž×” ×œ×¢×©×•×ª ×‘-5 ×”×“×§×•×ª ×”×‘××•×ª",
    "closing_move": "××™×š ×œ×”×ª×§×“× ×œ×¡×’×™×¨×”"
  },
  "coach_notes": {
    "doing_well": "×ž×” ××ª×” ×¢×•×©×” ×˜×•×‘",
    "needs_improvement": "×ž×” ×œ×©×¤×¨",
    "risk_assessment": "×¡×™×›×•× ×™× ×‘×©×™×—×” ×”×–×•"
  }
}

ðŸŽ¯ ×—×©×•×‘ ×‘×ž×™×•×—×“:
- ×›×œ ×”×ª×©×•×‘×•×ª ×‘×¢×‘×¨×™×ª ×ž×§×¦×•×¢×™×ª
- ×ª×Ÿ ×ª×©×•×‘×•×ª ×¡×¤×¦×™×¤×™×•×ª, ×œ× ×›×œ×œ×™×•×ª
- ×”×ª×™×™×—×¡ ×œ×§×•× ×˜×§×¡×˜ ×”×ž×“×•×™×§ ×©×œ ×”×©×™×—×”
- ×–×”×” ×¨×ž×–×™× ×¢×“×™× ×™× ×©×œ ×”×œ×§×•×—
- ×ª×Ÿ ×’× "×ž×” ×œ× ×œ×•×ž×¨" - ×–×” ×§×¨×™×˜×™!
- ×”×™×” ×™×©×™×¨ ×•××¡×¨×˜×™×‘×™ ×‘×¢×¦×•×ª
- ×× ×™×© ×¡×™×›×•×Ÿ ×œ××‘×“ ××ª ×”×¢×¡×§×” - ××ž×¨ ××ª ×–×”!

×“×•×’×ž××•×ª ×œ×–×™×”×•×™ ××•×ª×•×ª ×§× ×™×™×”:
âŒ "×ª×•×“×” ×¢×œ ×”×ž×™×“×¢" = ×œ× ××•×ª ×§× ×™×™×”
âœ… "××™×š ×–×” ×¢×•×‘×“ ××¦×œ ×—×‘×¨×•×ª ×›×ž×• ×©×œ× ×•?" = ××•×ª ×§× ×™×™×” ×—×–×§
âœ… "×ž×” ×œ×•×§×— ×‘×“×¨×š ×›×œ×œ ×”×”×˜×ž×¢×”?" = ××•×ª ×§× ×™×™×”
âœ… "×›×ž×” ×–×” ×¢×•×œ×”?" = ××•×ª ×§× ×™×™×” (×× ×‘× ××—×¨×™ ×©×“×™×‘×¨× ×• ×¢×œ ×”×‘×¢×™×”)

×”×™×” ×”×—×‘×¨ ×”×›×™ ×˜×•×‘ ×©×œ ×”×ž×•×›×¨ - ×™×©×™×¨, ××ž×™×ª×™, ×•×ª×•×ž×š ×‘×”×¦×œ×—×” ×©×œ×•!`;
  }

  /**
   * Stream completion from OpenAI
   */
  async streamCompletion(conversationContext, onChunk, onComplete, onError) {
    let timeoutId = null;
    try {
      // Create new abort controller with timeout
      this.abortController = new AbortController();

      // Set timeout (30 seconds)
      timeoutId = setTimeout(() => {
        console.warn('â±ï¸ OpenAI request timeout after 30 seconds');
        this.abortController.abort();
      }, 30000);

      // Add user message to history
      this.conversationHistory.push({
        role: 'user',
        content: `CURRENT CONVERSATION:\n${conversationContext}\n\nProvide your expert coaching response in JSON format.`
      });

      // Limit history to last 10 messages
      if (this.conversationHistory.length > 20) {
        this.conversationHistory = this.conversationHistory.slice(-20);
      }

      // Make streaming request
      const response = await fetch(this.apiUrl, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          'Authorization': `Bearer ${this.apiKey}`
        },
        body: JSON.stringify({
          model: this.model,
          messages: [
            { role: 'system', content: this.systemPrompt },
            ...this.conversationHistory
          ],
          temperature: 0.7,
          max_tokens: 1000,
          stream: true // Enable streaming!
        }),
        signal: this.abortController.signal
      });

      // Clear timeout on successful connection
      if (timeoutId) {
        clearTimeout(timeoutId);
        timeoutId = null;
      }

      if (!response.ok) {
        throw new Error(`OpenAI API error: ${response.status}`);
      }

      // Process stream
      const reader = response.body.getReader();
      const decoder = new TextDecoder();
      let buffer = '';
      let fullContent = '';

      while (true) {
        const { done, value } = await reader.read();

        if (done) break;

        // Decode chunk
        const chunk = decoder.decode(value, { stream: true });
        buffer += chunk;

        // Process complete lines
        const lines = buffer.split('\n');
        buffer = lines.pop() || ''; // Keep incomplete line in buffer

        for (const line of lines) {
          if (line.trim() === '') continue;
          if (line.trim() === 'data: [DONE]') continue;

          if (line.startsWith('data: ')) {
            try {
              const data = JSON.parse(line.slice(6));
              const content = data.choices?.[0]?.delta?.content;

              if (content) {
                fullContent += content;

                // Call chunk callback with incremental update
                onChunk({
                  delta: content,
                  fullContent: fullContent,
                  done: false
                });
              }

            } catch (parseError) {
              console.warn('Error parsing SSE data:', parseError);
            }
          }
        }
      }

      // Parse final JSON response
      let suggestion;
      try {
        // Extract JSON from markdown code blocks if present
        let jsonContent = fullContent;
        const jsonMatch = fullContent.match(/```json\n?([\s\S]*?)\n?```/);
        if (jsonMatch) {
          jsonContent = jsonMatch[1];
        }

        suggestion = JSON.parse(jsonContent);
      } catch (parseError) {
        console.error('Error parsing final JSON:', parseError);
        // Fallback to basic structure
        suggestion = {
          suggestions: {
            main_advice: fullContent,
            quick_replies: [],
            why: 'AI response'
          }
        };
      }

      // Add to conversation history
      this.conversationHistory.push({
        role: 'assistant',
        content: fullContent
      });

      // Call complete callback
      onComplete({
        suggestion,
        fullContent,
        done: true
      });

      return suggestion;

    } catch (error) {
      // Clear timeout on error
      if (timeoutId) {
        clearTimeout(timeoutId);
      }

      if (error.name === 'AbortError') {
        console.log('Stream aborted by user or timeout');
        onError(new Error('Request was cancelled or timed out'));
        return null;
      }

      console.error('Error streaming from OpenAI:', error);
      onError(error);
      throw error;
    }
  }

  /**
   * Cancel ongoing stream
   */
  cancelStream() {
    if (this.abortController) {
      this.abortController.abort();
      this.abortController = null;
    }
  }

  /**
   * Quick analysis without full coaching
   */
  async quickAnalysis(text) {
    try {
      const response = await fetch(this.apiUrl, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          'Authorization': `Bearer ${this.apiKey}`
        },
        body: JSON.stringify({
          model: 'gpt-3.5-turbo', // Faster for quick analysis
          messages: [
            {
              role: 'system',
              content: 'Analyze this sales conversation snippet. Respond with JSON: {"sentiment": "positive|neutral|negative", "signals": [], "urgency": 1-10}'
            },
            {
              role: 'user',
              content: text
            }
          ],
          temperature: 0.3,
          max_tokens: 200
        })
      });

      if (!response.ok) {
        throw new Error(`OpenAI API error: ${response.status}`);
      }

      const data = await response.json();
      const content = data.choices[0].message.content;

      return JSON.parse(content);

    } catch (error) {
      console.error('Error in quick analysis:', error);
      return null;
    }
  }

  /**
   * Detect speaker role (salesperson vs client)
   */
  async detectSpeaker(text, previousContext = '') {
    try {
      const prompt = `Based on this conversation, is the speaker the SALESPERSON or the CLIENT?

Previous context: ${previousContext}

Current statement: "${text}"

Respond with just one word: SALESPERSON or CLIENT`;

      const response = await fetch(this.apiUrl, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          'Authorization': `Bearer ${this.apiKey}`
        },
        body: JSON.stringify({
          model: 'gpt-3.5-turbo',
          messages: [
            { role: 'system', content: 'You are a speaker identification system.' },
            { role: 'user', content: prompt }
          ],
          temperature: 0.1,
          max_tokens: 10
        })
      });

      const data = await response.json();
      const result = data.choices[0].message.content.trim().toUpperCase();

      return result === 'CLIENT' ? 'client' : 'salesperson';

    } catch (error) {
      console.error('Error detecting speaker:', error);
      return 'unknown';
    }
  }

  /**
   * Generate follow-up email
   */
  async generateFollowUpEmail(conversationSummary) {
    const prompt = `Based on this sales conversation, generate a professional follow-up email:

${conversationSummary}

Format:
Subject: [compelling subject line]
Body: [personalized email with clear next steps]

Keep it concise, value-focused, and action-oriented.`;

    try {
      const response = await fetch(this.apiUrl, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          'Authorization': `Bearer ${this.apiKey}`
        },
        body: JSON.stringify({
          model: this.model,
          messages: [
            { role: 'system', content: 'You are an expert sales email writer.' },
            { role: 'user', content: prompt }
          ],
          temperature: 0.7,
          max_tokens: 500
        })
      });

      const data = await response.json();
      return data.choices[0].message.content;

    } catch (error) {
      console.error('Error generating email:', error);
      return null;
    }
  }

  /**
   * Clear conversation history
   */
  clearHistory() {
    this.conversationHistory = [];
  }

  /**
   * Update configuration
   */
  updateConfig(config) {
    if (config.apiKey) this.apiKey = config.apiKey;
    if (config.model) this.model = config.model;
  }
}
